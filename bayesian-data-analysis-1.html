<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>7 Bayesian Data Analysis | Bayesian Workflow Using Stan</title>
  <meta name="description" content="7 Bayesian Data Analysis | Bayesian Workflow Using Stan, with examples and programming techniques.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="7 Bayesian Data Analysis | Bayesian Workflow Using Stan" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/logo-tm.pdf" />
  <meta property="og:description" content="7 Bayesian Data Analysis | Bayesian Workflow Using Stan, with examples and programming techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Bayesian Data Analysis | Bayesian Workflow Using Stan" />
  
  <meta name="twitter:description" content="7 Bayesian Data Analysis | Bayesian Workflow Using Stan, with examples and programming techniques." />
  <meta name="twitter:image" content="img/logo-tm.pdf" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="part-2-bayesian-inference.html">
<link rel="next" href="mle-chapter.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Bayesian Statistics with Stan</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a></li>
<li><a href="part-1-bayesian-workflow.html#part-1-bayesian-workflow"><i style="font-size: 110%; padding:1.5em 0 0 0; color:#990017;">Part 1: Bayesian Workflow</i></a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="fake-data-simulation.html"><a href="fake-data-simulation.html"><i class="fa fa-check"></i><b>2</b> Fake-data Simulation</a></li>
<li class="chapter" data-level="3" data-path="prior-distributions-and-models-for-data.html"><a href="prior-distributions-and-models-for-data.html"><i class="fa fa-check"></i><b>3</b> Prior Distributions and Models for Data</a></li>
<li class="chapter" data-level="4" data-path="some-self-contained-examples.html"><a href="some-self-contained-examples.html"><i class="fa fa-check"></i><b>4</b> Some Self-Contained Examples</a></li>
<li class="chapter" data-level="5" data-path="workflow-in-action.html"><a href="workflow-in-action.html"><i class="fa fa-check"></i><b>5</b> Workflow in Action</a></li>
<li class="chapter" data-level="6" data-path="modeling-as-software-development.html"><a href="modeling-as-software-development.html"><i class="fa fa-check"></i><b>6</b> Modeling as Software Development</a></li>
<li><a href="part-2-bayesian-inference.html#part-2-bayesian-inference"><i style="font-size: 110%; color:#990017;">Part 2: Bayesian Inference</i></a></li>
<li class="chapter" data-level="7" data-path="bayesian-data-analysis-1.html"><a href="bayesian-data-analysis-1.html"><i class="fa fa-check"></i><b>7</b> Bayesian Data Analysis</a></li>
<li class="chapter" data-level="8" data-path="mle-chapter.html"><a href="mle-chapter.html"><i class="fa fa-check"></i><b>8</b> Penalized Maximum Likelihood Point Estimation</a></li>
<li class="chapter" data-level="9" data-path="bayesian-point-estimation.html"><a href="bayesian-point-estimation.html"><i class="fa fa-check"></i><b>9</b> Bayesian Point Estimation</a></li>
<li class="chapter" data-level="10" data-path="vi-advanced-chapter.html"><a href="vi-advanced-chapter.html"><i class="fa fa-check"></i><b>10</b> Variational Inference</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Workflow Using Stan</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayesian-data-analysis-1" class="section level1">
<h1><span class="header-section-number">7</span> Bayesian Data Analysis</h1>
<div id="model-building" class="section level2">
<h2><span class="header-section-number">7.1</span> Model Building</h2>
</div>
<div id="inference" class="section level2">
<h2><span class="header-section-number">7.2</span> Inference</h2>
<div id="basic-quantities" class="section level3 unnumbered">
<h3>Basic Quantities</h3>
<p>The mechanics of Bayesian inference follow directly from Bayes’s rule. To fix notation, let <span class="math inline">\(y\)</span> represent observed quantities such as data and let <span class="math inline">\(\theta\)</span> represent unknown quantities such as parameters and future observations. Both <span class="math inline">\(y\)</span> and <span class="math inline">\(\theta\)</span> will be modeled as random. Let <span class="math inline">\(x\)</span> represent known, but unmodeled quantities such as constants, hyperparameters, and predictors.</p>
</div>
<div id="probability-functions" class="section level3 unnumbered">
<h3>Probability Functions</h3>
<p>The probability function <span class="math inline">\(p(y,\theta)\)</span> is the joint probability function of the data <span class="math inline">\(y\)</span> and parameters <span class="math inline">\(\theta\)</span>. The constants and predictors <span class="math inline">\(x\)</span> are implicitly understood as being part of the conditioning. The conditional probability function <span class="math inline">\(p(y|\theta)\)</span> of the data <span class="math inline">\(y\)</span> given parameters <span class="math inline">\(\theta\)</span> and constants <span class="math inline">\(x\)</span> is called the sampling probability function; it is also called the likelihood function when viewed as a function of <span class="math inline">\(\theta\)</span> for fixed <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>.</p>
<p>The probability function <span class="math inline">\(p(\theta)\)</span> over the parameters given the constants <span class="math inline">\(x\)</span> is called the prior because it characterizes the probability of the parameters before any data are observed. The conditional probability function <span class="math inline">\(p(\theta|y)\)</span> is called the posterior because it characterizes the probability of parameters given observed data <span class="math inline">\(y\)</span> and constants <span class="math inline">\(x\)</span>.</p>
</div>
<div id="bayess-rule" class="section level3 unnumbered">
<h3>Bayes’s Rule</h3>
<p>The technical apparatus of Bayesian inference hinges on the following chain of equations, known in various forms as Bayes’s rule (where again, the constants <span class="math inline">\(x\)</span> are implicit).</p>
<p><span class="math display">\[
\begin{array}{rcll}
p(\theta|y)  &amp; =  &amp; \displaystyle \frac{p(\theta,y)}{p(y)}
&amp;  \ \ \ \ \ \mbox{ [definition of  conditional probability]}
\\[16pt]
&amp; = &amp; \displaystyle \frac{p(y|\theta) \, p(\theta)}{p(y)}
&amp; \ \ \ \ \ \mbox{ [chain rule]}
\\[16pt]
&amp; = &amp; \displaystyle \frac{p(y|\theta) \, p(\theta)}
                        {\int_{\Theta} p(y,\theta) \, d\theta}
&amp; \ \ \ \ \ \mbox{ [law of total probability]}
\\[16pt]
&amp; = &amp; \displaystyle \frac{p(y|\theta) \, p(\theta)}
                        {\int_{\Theta} p(y|\theta) \, p(\theta) \, d\theta}
&amp; \ \ \ \ \ \mbox{ [chain rule]}
\\[16pt]
&amp; \propto &amp; \displaystyle p(y|\theta) \, p(\theta)
\end{array}
\]</span></p>
<p>Bayes’s rule “inverts” the probability of the posterior <span class="math inline">\(p(\theta|y)\)</span>, expressing it solely in terms of the likelihood <span class="math inline">\(p(y|\theta)\)</span> and prior <span class="math inline">\(p(\theta)\)</span> (again, with constants and predictors <span class="math inline">\(x\)</span> implicit). The last step is important for Stan, which only requires probability functions to be characterized up to a constant multiplier.</p>
</div>
<div id="predictive-inference" class="section level3 unnumbered">
<h3>Predictive Inference</h3>
<p>The uncertainty in the estimation of parameters <span class="math inline">\(\theta\)</span> from the data <span class="math inline">\(y\)</span> (given the model) is characterized by the posterior <span class="math inline">\(p(\theta|y)\)</span>. The posterior is thus crucial for Bayesian predictive inference.</p>
<p>If <span class="math inline">\(\tilde{y}\)</span> is taken to represent new, perhaps as yet unknown, observations, along with corresponding constants and predictors <span class="math inline">\(\tilde{x}\)</span>, then the posterior predictive probability function is given by</p>
<p><span class="math display">\[
p(\tilde{y}|y)
= \int_{\Theta} p(\tilde{y}|\theta)
                \, p(\theta|y) \, d\theta.
\]</span> Here, both the original constants and predictors <span class="math inline">\(x\)</span> and the new constants and predictors <span class="math inline">\(\tilde{x}\)</span> are implicit. Like the posterior itself, predictive inference is characterized probabilistically. Rather than using a point estimate of the parameters <span class="math inline">\(\theta\)</span>, predictions are made based on averaging the predictions over a range of <span class="math inline">\(\theta\)</span> weighted by the posterior probability <span class="math inline">\(p(\theta|y)\)</span> of <span class="math inline">\(\theta\)</span> given data <span class="math inline">\(y\)</span> (and constants <span class="math inline">\(x\)</span>).</p>
<p>The posterior may also be used to estimate event probabilities. For instance, the probability that a parameter <span class="math inline">\(\theta_k\)</span> is greater than zero is characterized probabilistically by</p>
<p><span class="math display">\[
\mbox{Pr}(\theta_k &gt; 0)
= \int_{\Theta} \mbox{I}(\theta_k &gt; 0) \, p(\theta|y) \, d\theta.
\]</span></p>
<p>The indicator function, <span class="math inline">\(\mbox{I}(\phi)\)</span>, evaluates to one if the proposition <span class="math inline">\(\phi\)</span> is true and evaluates to zero otherwise.</p>
<p>Comparisons involving future observables may be carried out in the same way. For example, the probability that <span class="math inline">\(\tilde{y}_n &gt; \tilde{y}_{n&#39;}\)</span> can be characterized using the posterior predictive probability function as <span class="math display">\[
\mbox{Pr}(\tilde{y}_n &gt; \tilde{y}_{n&#39;})
= \int_{\Theta} \int_{Y} \mbox{I}(\tilde{y}_n &gt; \tilde{y}_{n&#39;}) \,
p(\tilde{y}|\theta) p(\theta|y) \, d\tilde{y} \, d\theta.
\]</span></p>
</div>
</div>
<div id="model-checking-and-evaluation" class="section level2">
<h2><span class="header-section-number">7.3</span> Model Checking and Evaluation</h2>
<div id="fake-data-simulation-1" class="section level3 unnumbered">
<h3>Fake-Data Simulation</h3>
</div>
<div id="posterior-predictive-checking-1" class="section level3 unnumbered">
<h3>Posterior Predictive Checking</h3>
<p>After the parameters are fit to data, they can be used to simulate a new data set by running the model inferences in the forward direction. These replicated data sets can then be compared to the original data either visually or statistically to assess model fit <span class="citation">(Gelman et al. <a href="#ref-GelmanEtAl:2013">2013</a>, Chapter 6)</span>.</p>
<p>In Stan, posterior simulations can be generated in two ways. The first approach is to treat the predicted variables as parameters and then define their distributions in the model block. The second approach, which also works for discrete variables, is to generate replicated data using random-number generators in the generated quantities block.</p>
<!--
### Exploratory Data Analysis as Model Checking {-}

### Cross Validation {-}

## Model Expansion

## Decision Analysis
-->

</div>
</div>
</div>
<h3><i style="font-size: 110%; color:#990017;">References</i></h3>
<div id="refs" class="references">
<div id="ref-GelmanEtAl:2013">
<p>Gelman, Andrew, J. B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian Data Analysis</em>. Third. London: Chapman &amp;Hall/CRC Press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="part-2-bayesian-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mle-chapter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
